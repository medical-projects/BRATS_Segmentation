{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import random\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras \n",
    "\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, UpSampling2D, \\\n",
    "            Flatten, Dense, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import ResNet50, densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_class:\n",
    "    def __init__(self, pat_n, image, roi, n_serial):\n",
    "        \n",
    "        self.name = pat_n\n",
    "        self.image = image\n",
    "        self.roi = roi\n",
    "        self.mal = False\n",
    "        self.n_serial = n_serial\n",
    "        \n",
    "        if np.sum(roi) > 0:\n",
    "            self.mal = True\n",
    "        \n",
    "    def print_roi(self, cmap = 'plasma', linewidths = 0.5,  **args):\n",
    "        plt.contour(self.roi, cmap = cmap, linewidths = linewidths, **args)\n",
    "            \n",
    "    def print_image(self, cmap = 'gray', **args):\n",
    "        plt.imshow(self.image, cmap = 'gray', **args)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_sets(poss, negs, admitted_pos, num_test = 50 ):\n",
    "    negs.pop('Brats18_CBICA_AWI_1')\n",
    "    poss.pop('Brats18_CBICA_AWI_1')\n",
    "    \n",
    "    poss_shuffled = list(poss.keys())\n",
    "    random.shuffle(poss_shuffled)\n",
    "    \n",
    "    test_pts = poss_shuffled[ :num_test]\n",
    "    train_pts = poss_shuffled[num_test:]\n",
    "    \n",
    "    files_pos_train = reduce(lambda x,y:x+y, [poss[x] for x in train_pts])\n",
    "    files_neg_train = reduce(lambda x,y:x+y, [negs[x] for x in train_pts])\n",
    "\n",
    "    files_pos_train = [x for x in files_pos_train if x in admitted_pos]\n",
    "    random.shuffle(files_neg_train)\n",
    "    \n",
    "    files_train = files_pos_train + files_neg_train[:len(files_pos_train)]\n",
    "    \n",
    "    files_pos_test = reduce(lambda x,y:x+y, [poss[x] for x in test_pts])\n",
    "    files_neg_test = reduce(lambda x,y:x+y, [negs[x] for x in test_pts])\n",
    "    \n",
    "    files_pos_test = [x for x in files_pos_test if x in admitted_pos]\n",
    "    random.shuffle(files_neg_train)\n",
    "    \n",
    "    files_test = files_pos_test + files_neg_test[:len(files_pos_test)]\n",
    "    \n",
    "    \n",
    "    random.shuffle(files_train)\n",
    "    random.shuffle(files_test)\n",
    "    \n",
    "    return files_train, files_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=16, dim=(170, 140), n_channels=3,\n",
    "                  shuffle=True, OUT_SIZE = 2, TOP_K = 1, mode = 'train'):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.dim = dim # ?-1\n",
    "        self.OUT_SIZE = OUT_SIZE\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.TOP_K = TOP_K\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        self.aug = ImageDataGenerator(rotation_range=45, width_shift_range=0.1,\\\n",
    "                                      height_shift_range=0.1, horizontal_flip=True)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, self.OUT_SIZE), dtype='float32')\n",
    "        \n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            \n",
    "            with open('BRATS_preprocessed_/' + ID, 'rb') as filehandler:\n",
    "                photo = pickle.load(filehandler)\n",
    "                \n",
    "            img = photo.image\n",
    "            \n",
    "            XX = np.repeat(img.reshape(*self.dim, 1), 3, axis = 2)   \n",
    "            \n",
    "            if self.mode == 'train':\n",
    "                params = self.aug.get_random_transform(XX.shape)\n",
    "                X[i,] = self.aug.apply_transform(XX, params)\n",
    "            else:\n",
    "                X[i,] = XX\n",
    "            \n",
    "\n",
    "            if photo.mal:\n",
    "                y[i,:] = np.array([1.0, 0.0])\n",
    "\n",
    "            else:\n",
    "                y[i,:] = np.array([0.0, 1.0])  \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.max(K.round(y_pred), axis = -1), K.max(y_true, axis = -1)))\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "\n",
    "    c1 = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "    v1 = tf.math.multiply(1.0 - y_true, tf.math.log(1.0 - c1))\n",
    "    v2 = tf.math.multiply(y_true, tf.math.log(c1))\n",
    "\n",
    "    return -tf.reduce_mean(tf.add(v1, v2))#keras.losses.binary_crossentropy\n",
    "\n",
    "def create_model(mm_, lambd_reg = 5e-6, learning_rate = 5e-5, mu_reg = 1e-6):\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"weights\", reuse=tf.AUTO_REUSE):\n",
    "        w1 = tf.get_variable(\"w1\", shape=(256,1), trainable=True)\n",
    "        w2 = tf.get_variable(\"w2\", shape=(512,1), trainable=True)\n",
    "        w3 = tf.get_variable(\"w3\", shape=(1024,1), trainable=True)\n",
    "    #    w4 = tf.get_variable(\"w4\", shape=(32,1), trainable=True)\n",
    "    \n",
    "    \n",
    "    inp = mm_.input\n",
    "    \n",
    "    c_6 = mm_.get_layer(\"res2c_branch2c\")\n",
    "    #c_6.activity_regularizer = regularizers.l1(lambd_reg)\n",
    "    c_6 = ZeroPadding2D(padding=((1,0),(1,0)))(c_6.output)\n",
    "    \n",
    "    \n",
    "    c_18 = mm_.get_layer(\"res3d_branch2c\")\n",
    "    #c_18.activity_regularizer = regularizers.l1(lambd_reg)\n",
    "    c_18 = c_18.output\n",
    "    \n",
    "    c_42 = mm_.get_layer(\"res4f_branch2c\")\n",
    "    #c_42.activity_regularizer = regularizers.l1(lambd_reg)\n",
    "    c_42 = c_42.output\n",
    "    \n",
    "    '''\n",
    "    c_58 = mm_.get_layer(\"activation_49\")\n",
    "    #c_58.activity_regularizer = regularizers.l1(lambd_reg)\n",
    "    c_58 = c_58.output\n",
    "    '''\n",
    "    \n",
    "    def multy(a):\n",
    "        return lambda x: tf.tensordot(x, a, axes = [[-1],[0]])\n",
    "    \n",
    "    def add(a):\n",
    "        return tf.math.add(a[0], a[1])\n",
    "    \n",
    "    upsampling1 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", interpolation='bilinear')\n",
    "    upsampling2 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", interpolation='bilinear')\n",
    "    upsampling3 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", interpolation='bilinear')\n",
    "    \n",
    "    layer_4 = Lambda(multy(w3))(c_42)\n",
    "    layer_3 = Lambda(add)([upsampling1(layer_4), Lambda(multy(w2))(c_18)])\n",
    "    layer_2 = Lambda(add)([upsampling2(layer_3), Lambda(multy(w1))(c_6)])\n",
    "\n",
    "    conv = Conv2D(1, (1,1), name = 'Conv_Sigmoid', \n",
    "                  activity_regularizer = regularizers.l1(mu_reg),\\\n",
    "                  activation = 'sigmoid')(layer_2)\n",
    "    \n",
    "    out = Dense(2, activation = 'softmax')(Flatten()(conv))\n",
    "    \n",
    "    \n",
    "    model_train = Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    #for layer in model_train.layers:\n",
    "    #    layer.kernel_regularizer = regularizers.l2(lambd_reg)\n",
    "        \n",
    "    model_image = Model(inputs = inp, outputs = conv)\n",
    "    \n",
    "    adam = Adam(learning_rate)\n",
    "    \n",
    "    #model_train.compile(optimizer = adam, loss = custom_loss, metrics = [custom_acc])\n",
    "    model_train.compile(optimizer = adam, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model_train, model_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patients_pos', 'rb') as filehandler:\n",
    "    patients_pos = pickle.load(filehandler)\n",
    "    \n",
    "with open('patients_neg', 'rb') as filehandler:\n",
    "    patients_neg = pickle.load(filehandler)\n",
    "    \n",
    "with open('10_percent_lesions', 'rb') as filehandler:\n",
    "    admitted_pos = pickle.load(filehandler)   \n",
    "    \n",
    "train_namespace, val_namespace = create_train_test_sets(\\\n",
    "                patients_pos, patients_neg, admitted_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = densenet.DenseNet121(include_top = False, weights = 'imagenet', input_shape = (170, 140, 3))\n",
    "\n",
    "model = ResNet50(include_top=False, weights='imagenet', input_shape = (170, 140, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm, mm_image = create_model(model)\n",
    "\n",
    "training_generator = DataGenerator(train_namespace, mode = 'train')\n",
    "validation_generator = DataGenerator(val_namespace, mode = 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.fit_generator(generator=training_generator,\n",
    "                validation_data=validation_generator,\n",
    "                use_multiprocessing=True,\n",
    "                 #callbacks=callbacks_list,\n",
    "                workers=4, verbose = 1, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_map(image, dims_tr = (44, 34)):\n",
    "    h, w = image.shape\n",
    "    \n",
    "    image_tr = np.zeros(dims_tr)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if image[i,j] > 0:\n",
    "                image_tr[int((i / h) // (1.0 / dims_tr[0])),\n",
    "                     int((j / w) // (1.0 / dims_tr[1]))] = 1.0\n",
    "            \n",
    "    return image_tr\n",
    "\n",
    "for ID in val_namespace:\n",
    "#ID = namespace[400]\n",
    "\n",
    "\n",
    "    with open('BRATS_preprocessed_/' + ID, 'rb') as filehandler:\n",
    "        photo = pickle.load(filehandler)\n",
    "        \n",
    "    photo.print_image()\n",
    "    photo.print_roi()\n",
    "    plt.show()\n",
    "    \n",
    "    img = downsample_map(photo.roi, dims_tr = (44, 34))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ID in val_namespace:\n",
    "#ID = namespace[400]\n",
    "\n",
    "\n",
    "    with open('BRATS_preprocessed_/' + ID, 'rb') as filehandler:\n",
    "        photo = pickle.load(filehandler)\n",
    "\n",
    "    print(photo.mal)\n",
    "    #with open('Data_original/Original/' + ID, 'rb') as filehandler:\n",
    "    #    photo = pickle.load(filehandler, encoding = 'latin1')\n",
    "\n",
    "\n",
    "    pred = mm_image.predict(np.repeat(photo.image.reshape(1, 170, 140, 1), 3, axis=3))\n",
    "    photo.print_image()\n",
    "    photo.print_roi()\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(pred.reshape((44,36)), cmap = 'Blues')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1584 / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_pos = reduce(lambda x,y:x+y, patients_pos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admitted_positives = []\n",
    "\n",
    "for i, name in enumerate(all_files_pos):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    with open('BRATS_preprocessed/' + name, 'rb') as filehandler:\n",
    "        img = pickle.load(filehandler)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('BRATS_preprocessed/Brats18_2013_4_1_119', 'rb') as filehandler:\n",
    "    img = pickle.load(filehandler)\n",
    "\n",
    "img.print_roi(cmap = 'Reds')\n",
    "img.print_image()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = np.sum(img.roi > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Brats18_2013_4_1_120' in patients_pos['Brats18_2013_4_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sum([], patients_pos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([[1,2,3], [4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.array([[1,2,3],[4,5,6]]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(img.image, (140, 170))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [patients_pos[x][0] for x in patients_pos if len(patients_pos[x]) > 0]:\n",
    "    with open('BRATS_preprocessed/' + file ,'rb') as filehandler:\n",
    "        img = pickle.load(filehandler)\n",
    "    print(file)    \n",
    "    img.print_roi(cmap = 'Reds')\n",
    "    img.print_image()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([patients_pos[x][0] for x in patients_pos if '2013' in x and len(patients_pos[x]) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients_pos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
